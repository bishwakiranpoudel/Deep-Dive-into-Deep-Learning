{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# YOLO ( You only look once )\n",
        "### Key Innovations\n",
        "- Unified Detection Framework: Combines object localization and classification tasks into a single neural netowrk\n",
        "\n",
        "- Grid Based Prediction: Divides the image into S x S grid. Each grid cell predicts: B bounding boxes with associated confidence scores, C class probablities\n",
        "\n",
        "- Real time processing: Achieves high speed inference suitable for real-world applications.\n",
        "\n",
        "- End to End training: Simplifies the object detection pipeline compared to traditional multistage approaches.\n",
        "\n",
        "### Architectural Overview\n",
        "- Backbone: A CNN such as Darknet, extracts spatial features frm the input image.\n",
        "\n",
        "- Fully connected layer predicts: Bounding Box coordinates, confidence score, class probablities."
      ],
      "metadata": {
        "id": "xk3k9G59Lj3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n"
      ],
      "metadata": {
        "id": "Z15YxwBdMpMq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class YOLO(nn.Module):\n",
        "  def __init__(self, grid_size=7, num_boxes = 2, num_classes = 20):\n",
        "    super(YOLO, self).__init__()\n",
        "    self.grid_size = grid_size\n",
        "    self.num_boxes = num_boxes\n",
        "    self.num_classes = num_classes\n",
        "\n",
        "    # backbone\n",
        "    self.feature_extractor = nn.Sequential(\n",
        "        nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        ## Additional conv layers....\n",
        "    )\n",
        "\n",
        "    self.fc= nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(512 * grid_size * grid_size, 4096),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(4096, 7 * 7 * 30),\n",
        "    )\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.feature_extractor(x)\n",
        "      x = self.fc(x)\n",
        "      x = x.view(-1, self.grid_size, self.grid_size, self.num_boxes * 5 + self.num_classes)\n",
        "      return x"
      ],
      "metadata": {
        "id": "FCAlP5HlMx1Q"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class YOLOLoss(nn.Module):\n",
        "    def __init__(self, lambda_coord=5, lambda_noobj=0.5):\n",
        "        super(YOLOLoss, self).__init__()\n",
        "        self.lambda_coord = lambda_coord\n",
        "        self.lambda_noobj = lambda_noobj\n",
        "\n",
        "    def forward(self, predictions, targets):\n",
        "        # Parse predictions and targets\n",
        "        pred_boxes = predictions[..., :4]\n",
        "        pred_conf = predictions[..., 4]\n",
        "        pred_classes = predictions[..., 5:]\n",
        "\n",
        "        true_boxes = targets[..., :4]\n",
        "        true_conf = targets[..., 4]\n",
        "        true_classes = targets[..., 5:]\n",
        "\n",
        "        # Calculate loss components\n",
        "        coord_loss = self.lambda_coord * torch.sum((pred_boxes - true_boxes) ** 2)\n",
        "        conf_loss = torch.sum((pred_conf - true_conf) ** 2)\n",
        "        class_loss = torch.sum((pred_classes - true_classes) ** 2)\n",
        "\n",
        "        total_loss = coord_loss + conf_loss + class_loss\n",
        "        return total_loss\n"
      ],
      "metadata": {
        "id": "okGnUXu0M_HL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a dataset (e.g., Pascal VOC)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((448, 448)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "dataset = datasets.VOCDetection(root=\"path_to_data\", year=\"2012\", image_set=\"train\", download=True, transform=transform)\n",
        "data_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = YOLO(grid_size=7, num_boxes=2, num_classes=20)\n",
        "criterion = YOLOLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(50):\n",
        "    for images, targets in data_loader:\n",
        "        predictions = model(images)\n",
        "        loss = criterion(predictions, targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n"
      ],
      "metadata": {
        "id": "G3_KZ4b2Nn9a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}